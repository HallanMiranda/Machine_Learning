{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefas do dia \n",
    "1. Rafaça o código de treinamento da aula 12: \n",
    "    - “K-Nearest Neighbors - Prática” no seu computador usando o Jupyter Notebook ou o Google Colabs.\n",
    "    OK\n",
    "2. Retreino o algoritmo com os seguintes valores para\n",
    "    - K: [3, 5, 7, 9, 11, 13, 15, 17, 19 e 21] e anote a acurácia. \n",
    "    OK\n",
    "3. Qual o problema principal de usar a métrica acurácia? \n",
    "    - Escreve um exemplo hipotético, no qual o problema acontece.\n",
    "   R: O problema principal de usar a métrica acurácia é que ela pode ser enganosa em situações em que as\n",
    "    classes estão desbalanceadas. A acurácia é calculada como a proporção de amostras corretamente classificadas\n",
    "    em relação ao total de amostras. No entanto, em um cenário com classes desbalanceadas, em que uma classe\n",
    "    é muito mais frequente do que a outra, um classificador pode ter uma alta acurácia simplesmente classificando\n",
    "    todas as instâncias como pertencentes à classe majoritária. Isso ocorre porque a maioria das previsões\n",
    "    estará correta para a classe majoritária, mas muito poucas previsões serão corretas para a classe minoritária.\n",
    "    Portanto, a acurácia pode não fornecer uma visão precisa do desempenho do classificador.\n",
    "\n",
    "   Exemplo hipotético: Considere um conjunto de dados em que 90% das amostras pertencem à classe A\n",
    "   e 10% pertencem à classe B. Um classificador que sempre prevê a classe A teria uma acurácia de 90%. \n",
    "   No entanto, isso não significa que o classificador seja bom na detecção da classe B, \n",
    "   que pode ser mais importante ou relevante para o problema em questão.   \n",
    "\n",
    "4. Explique com um pequeno texto ilustrando a diferença entre:\n",
    "    - métrica de Precision e Recall e mostrando quando usa deve ser escolhida em relação a outra.\n",
    "\n",
    "R: A métrica de Precision (precisão) e Recall (revocação) são métricas utilizadas na avaliação de classificadores binários.\n",
    "A precisão é a proporção de verdadeiros positivos (TP) em relação ao total de instâncias previstas como positivas, ou seja,\n",
    "ela mede a precisão das previsões positivas. A fórmula para calcular a precisão é: Precision = TP / (TP + FP)\n",
    "\n",
    "R: O recall é a proporção de verdadeiros positivos em relação ao total de instâncias verdadeiramente positivas, ou seja,\n",
    "mede a capacidade do classificador de encontrar todas as instâncias positivas. A fórmula para calcular o recall é: Recall = TP / (TP + FN)\n",
    "\n",
    "A escolha entre precisão e recall depende do contexto do problema e das necessidades específicas do usuário.\n",
    "\n",
    "Precision é útil quando o foco principal é minimizar os falsos positivos, ou seja, evitar prever erroneamente uma instância como positiva\n",
    "quando ela é na verdade negativa. Por exemplo, em um sistema de detecção de spam de e-mails, é importante ter uma alta precisão para garantir\n",
    "que poucos e-mails legítimos sejam classificados como spam.\n",
    "\n",
    "Recall é útil quando o objetivo principal é minimizar os falsos negativos, ou seja, evitar que instâncias positivas sejam erroneamente previstas\n",
    "como negativas. Por exemplo, em um sistema de diagnóstico médico, é crucial ter um alto recall para garantir que poucas condições médicas graves\n",
    "sejam negligenciadas.\n",
    "\n",
    "5. Escreve um trecho de código que automatize o treinamento do algoritmo\n",
    "    - K-NN, a fim de encontrar o melhor valor para K, do exercício 2.\n",
    "    OK\n",
    "6. Escreva um pequeno texto, explicando as 6 denominações da\n",
    "    - matriz de confusão: P, N, TP, FN, FP e TN\n",
    "A matriz de confusão é uma tabela que resume o desempenho de um modelo de classificação em um conjunto de dados de teste. \n",
    "As seis denominações da matriz de confusão são:\n",
    "\n",
    "P (Positivo): Representa as instâncias da classe positiva.\n",
    "\n",
    "N (Negativo): Representa as instâncias da classe negativa.\n",
    "\n",
    "TP (True Positive): Representa as instâncias positivas que foram corretamente classificadas como positivas.\n",
    "\n",
    "FN (False Negative): Representa as instâncias positivas que foram incorretamente classificadas como negativas.\n",
    "\n",
    "FP (False Positive): Representa as instâncias negativas que foram incorretamente classificadas como positivas.\n",
    "\n",
    "TN (True Negative): Representa as instâncias negativas que foram corretamente classificadas como negativas.\n",
    "\n",
    "Essas denominações são utilizadas para calcular várias métricas de avaliação, como precisão, revocação e acurácia, que fornecem insights sobre o desempenho do modelo de classificação.    \n",
    "\n",
    "7. No conjunto de dados usado na aula 12: “K-Nearest Neighbors - Prática”, existe alguma variável que fere as premissas do K-NN?\n",
    "   Se sim ou não, explique.\n",
    "   \n",
    "R: sim tem duas variaveis object e umas das premissas do knn e que sejam variaveis numericas.    \n",
    "    As premissas do algoritmo K-NN (K-Vizinhos Mais Próximos) são:\n",
    "Variáveis numéricas contínuas: O K-NN é adequado para lidar com variáveis numéricas contínuas. \n",
    "Ele utiliza a distância euclidiana ou outras métricas de distância para calcular a proximidade entre instâncias.\n",
    "Espaço Euclidiano: O K-NN assume que os dados estão em um espaço euclidiano, ou seja, as distâncias entre as instâncias\n",
    "são medidas usando a geometria euclidiana. Portanto, é importante garantir que as variáveis sejam numericamente comparáveis\n",
    " e que a distância euclidiana seja uma métrica válida para medir a semelhança entre as instâncias.\n",
    "Instâncias próximas são semelhantes: O K-NN pressupõe que instâncias semelhantes tendem a estar próximas umas das outras\n",
    "no espaço de recursos.Isso significa que, para que o K-NN funcione corretamente, é necessário que as amostras do mesmo rótulo \n",
    "estejam agrupadas e separadas de outras classes.\n",
    "Conjunto de treinamento representativo: O K-NN assume que o conjunto de treinamento é uma representação adequada da população geral.\n",
    "Isso implica que o conjunto de treinamento deve abranger adequadamente a variabilidade dos dados e capturar todas as possíveis combinações\n",
    "de características que ocorrerão durante o teste.\n",
    "É importante ter em mente essas premissas ao aplicar o algoritmo K-NN, pois violações dessas premissas podem afetar o desempenho e a eficácia\n",
    "do modelo. Caso as premissas não sejam atendidas, pode ser necessário considerar outros algoritmos de classificação mais adequados para o conjunto\n",
    "de dados em questão.\n",
    "\n",
    "8. Faça a seguinte bateria de testes\n",
    "\n",
    "8.1 Class balanceada originalmente:\n",
    "\n",
    "    1. Faça a matriz de confusão, calcule a acurácia, recall e precision do conjunto de dados original\n",
    "\n",
    "    2. Anote os resultados. \n",
    "\n",
    "Matriz de Confusão:\n",
    " [[ 146 1359]\n",
    " [ 102 7893]]\n",
    "Acurácia: 0.8462105263157895\n",
    "Precision: 0.5887096774193549\n",
    "Recall: 0.09700996677740864\n",
    "Melhores parâmetros:  {'n_neighbors': 21}\n",
    "Melhor acurácia média:  0.83789457102763\n",
    "\n",
    "8.2 Classe balanceada:\n",
    "    1. Mantenha a proporção de 50% das linhas da planilha de dados com exemplos da classe “Conceder” e 50% com a classe “Negar”.\n",
    "\n",
    "    2. Faça a matriz de confusão, calcule a acurácia, recall e precision.\n",
    "\n",
    "    3. Anote os resultados.\n",
    "\n",
    "Matriz de Confusão:\n",
    " [[  33  576]\n",
    " [  30 3160]]\n",
    "Acurácia: 0.8404843379836799\n",
    "Precision: 0.5238095238095238\n",
    "Recall: 0.054187192118226604\n",
    "Melhores parâmetros:  {'n_neighbors': 21}\n",
    "Melhor acurácia média:  0.8381160133621857    \n",
    "\n",
    "        \n",
    "8.3 Classe desbalanceada 90/10\n",
    "    1. Mantenha a proporção de 90% das linhas da planilha de dados com exemplos da classe “Conceder” e 10% com a classe “Negar”.\n",
    "\n",
    "    2. Faça a matriz de confusão, calcule a acurácia, recall e precision.\n",
    "\n",
    "    3. Anote os resultados.\n",
    "\n",
    "Matriz de Confusão:\n",
    " [[1354    0]\n",
    " [  69   10]]\n",
    "Acurácia: 95.18%\n",
    "Precision: 0.9515108924806747\n",
    "Recall: 1.0\n",
    "Melhores parâmetros:  {'n_neighbors': 7}\n",
    "Melhor acurácia média:  0.950457744073239\n",
    "\n",
    "\n",
    "8.4 Refaça o exercícios 8.3 com as seguintes variações: 80/20, 70/30 e 60/40\n",
    "\n",
    "8.5 Crie um tabela de comparação entre os resultados das 3 métricas ( acurácia, recall e precision ) \n",
    "    para cada uma das proporções ( 50/50, 90/10, 80/20, 70/30, 60/40 ) e responda as seguintes perguntas:\n",
    "\n",
    "    1. Como a métrica da acurácia se comporta com a variação do desbalanceamento do conjunto de dados?\n",
    "\n",
    "    2. O que acontece com a métrica “Precison” e “Recall” a medida que os conjunto de dados tendem ao balanceamento de 50/50?\n",
    "\n",
    "    3. Observando as respostas anteriores, quais são as ações que aumentam ou diminuem a métrica de “Precision” ou “Recall” \n",
    "    de um problema de negócio?\n",
    "     \n",
    "8.6 Escreva um artigo para blog da Comunidade DS, descrevendo o seu aprendizado em relação ao comportamento das métricas de Precision,\n",
    " Recall e Acurácia a partir dos seus experimentos com os dados desbalanceados.\n",
    "\n",
    "\n",
    " Para realizar a bateria de testes proposta, é necessário ter acesso aos dados e ao algoritmo de classificação utilizado. Sem essas informações, não é possível realizar os cálculos e análises solicitados. No entanto, posso fornecer uma explicação geral sobre o comportamento das métricas de Precision, Recall e Acurácia em relação ao desbalanceamento dos dados.\n",
    "\n",
    "O desbalanceamento de classes em um conjunto de dados ocorre quando uma classe tem um número significativamente maior ou menor de exemplos em comparação com outras classes. Isso pode afetar o desempenho das métricas de avaliação do modelo. Vamos analisar cada uma das perguntas propostas:\n",
    "\n",
    "8.5.1. Acurácia:\n",
    "A métrica de acurácia é influenciada pelo desbalanceamento dos dados. Quando as classes estão desbalanceadas, ou seja, uma classe tem uma frequência muito maior ou menor em relação à outra, o modelo pode ter um viés em direção à classe majoritária. Isso pode levar a um alto valor de acurácia, que não reflete necessariamente a capacidade do modelo em prever corretamente as instâncias da classe minoritária. Portanto, em conjuntos de dados desbalanceados, a acurácia pode ser enganosa e não fornecer uma medida precisa da qualidade do modelo.\n",
    "\n",
    "8.5.2. Precision e Recall:\n",
    "A medida que o conjunto de dados tende a um balanceamento de 50/50, espera-se que as métricas de Precision e Recall se aproximem e sejam equilibradas para ambas as classes. Precision mede a proporção de exemplos classificados corretamente como positivos em relação ao total de exemplos classificados como positivos, enquanto Recall mede a proporção de exemplos positivos corretamente classificados em relação ao total de exemplos positivos no conjunto de dados. Em um conjunto de dados desbalanceado, onde a classe minoritária é rara em relação à classe majoritária, é comum observar um alto Recall para a classe majoritária, mas um baixo Recall para a classe minoritária. Isso ocorre porque o modelo pode estar focando principalmente na classe majoritária para obter uma alta acurácia geral.\n",
    "\n",
    "8.5.3. Ações para aumentar Precision ou Recall:\n",
    "Para melhorar a métrica de Precision, é necessário focar em reduzir os falsos positivos, ou seja, os exemplos que são erroneamente classificados como positivos. Isso pode ser feito ajustando o limiar de classificação do modelo ou aplicando técnicas de ajuste de custo que penalizam mais os erros de classificação da classe positiva.\n",
    "\n",
    "Para melhorar a métrica de Recall, é necessário focar em reduzir os falsos negativos, ou seja, os exemplos positivos que são erroneamente classificados como negativos. Isso pode ser alcançado ajustando o limiar de classificação do modelo ou aplicando técnicas de balanceamento de dados, como oversampling (gerando mais exemplos da classe minoritária) ou undersampling (reduzindo o número de exemplos da classe majoritária).\n",
    "\n",
    "8.6. Artigo para o blog da Comunidade DS:\n",
    "Como a resposta é extensa, não é possível fornecer um artigo completo neste contexto. No entanto, para escrever um artigo sobre o aprendizado em relação ao comportamento das métricas de Precision, Recall e Acurácia com dados desbalanceados, você pode seguir a estrutura abaixo:\n",
    "\n",
    "Introdução: Apresente o problema do desbalanceamento de classes em conjuntos de dados e a importância de compreender o comportamento das métricas de avaliação.\n",
    "\n",
    "Explicação das métricas: Descreva brevemente as métricas de Precision, Recall e Acurácia e sua relevância na avaliação de modelos de classificação.\n",
    "\n",
    "Experimentos: Descreva os experimentos realizados com dados desbalanceados, incluindo as diferentes proporções de classes e os resultados obtidos para cada métrica.\n",
    "\n",
    "Análise dos resultados: Analise os resultados obtidos e discuta como o desbalanceamento afeta as métricas e a interpretação dos resultados do modelo.\n",
    "\n",
    "Ações para melhorar as métricas: Explique as possíveis ações que podem ser tomadas para melhorar as métricas de Precision e Recall em conjuntos de dados desbalanceados.\n",
    "\n",
    "Considerações finais: Conclua o artigo resumindo as principais descobertas e destacando a importância de considerar o desbalanceamento de classes ao avaliar modelos de classificação.\n",
    "\n",
    "Lembre-se de fornecer exemplos práticos e ilustrativos ao longo do artigo para facilitar a compreensão dos leitores.\n",
    "\n",
    "\n",
    "Para treinar um modelo KNN (K-Nearest Neighbors) para classificação, você pode seguir os seguintes passos:\n",
    "\n",
    "1 - Importe as bibliotecas necessárias:\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "2- Carregue os dados de treinamento e teste e separe as features (características) e os rótulos (labels) do conjunto de dados:\n",
    "\n",
    "Carregue os dados de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "3- Certifique-se de ter suas features e labels preparadas em arrays NumPy ou estruturas de dados semelhantes.\n",
    "\n",
    "Pré-processe os dados:\n",
    "É comum aplicar uma etapa de pré-processamento nos dados antes de treinar um modelo KNN. Um pré-processamento comum é a normalização das features para garantir que todas tenham a mesma escala. Aqui, usaremos a padronização (StandardScaler) para normalizar as features:\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "4- Crie uma instância do modelo KNN:\n",
    "    k = 3  # número de vizinhos\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "5- Defina o número de vizinhos (k) que o modelo KNN usará para classificar os pontos.\n",
    "    Treine o modelo KNN:    \n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "6- Faça previsões usando o modelo treinado:\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "7- Avalie o desempenho do modelo:\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "A acurácia é uma métrica comum para avaliar modelos de classificação. Ela representa a proporção de previsões corretas em relação ao total de previsões.\n",
    "\n",
    "Lembre-se de adaptar esses passos ao seu conjunto de dados específico e às necessidades do seu problema de classificação. Isso inclui a preparação adequada das features e labels, a escolha dos parâmetros corretos (como o número de vizinhos) e a seleção adequada das métricas de avaliação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare os dados\n",
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negar', 'Conceder'], dtype=object)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Var resposta\n",
    "df.loc[:,'limite_adicional'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negar       7995\n",
      "Conceder    1505\n",
      "Name: limite_adicional, dtype: int64\n",
      "Negar       0.841579\n",
      "Conceder    0.158421\n",
      "Name: limite_adicional, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# contagem de quantos negar/conceder\n",
    "contagem = df.loc[:,'limite_adicional'].value_counts()\n",
    "# Porcentagem da quantidade Negar/Conceder\n",
    "porcentagem = df.loc[:,'limite_adicional'].value_counts(normalize=True)\n",
    "print(contagem)\n",
    "print(porcentagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjunto de dados X (features) e y (rótulos/classes)\n",
    "feactures = ['idade', 'saldo_atual', 'divida_atual', 'renda_anual',\n",
    "       'valor_em_investimentos', 'taxa_utilizacao_credito', 'num_emprestimos',\n",
    "       'num_contas_bancarias', 'num_cartoes_credito', 'dias_atraso_dt_venc',\n",
    "       'num_pgtos_atrasados', 'num_consultas_credito', 'taxa_juros', 'investe_exterior', 'pessoa_polit_exp']\n",
    "label = ['limite_adicional']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Divida os dados em conjunto de treinamento\n",
    "X_train = df.loc[:,feactures]\n",
    "y_train = df.loc[:,label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que 'x_train' seja o DataFrame que contém seus dados de treinamento e devemos excluir dados nao relevantes ou que nao seja float/int\n",
    "drop_n_relevante = ['investe_exterior', 'pessoa_polit_exp']\n",
    "X_train = X_train.drop(drop_n_relevante, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      " [[ 146 1359]\n",
      " [ 102 7893]]\n",
      "Acurácia: 84.62%\n",
      "Precision: 0.5887096774193549\n",
      "Recall: 0.09700996677740864\n",
      "Melhores parâmetros:  {'n_neighbors': 21}\n",
      "Melhor acurácia média:  0.83789457102763\n"
     ]
    }
   ],
   "source": [
    "# Aqui está um trecho de código que automatiza o treinamento do algoritmo K-NN \n",
    "# para encontrar o melhor valor para K, com base no exercício 2:\n",
    "\n",
    "# 2. Defina uma lista de valores K para experimentar\n",
    "k_values = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "\n",
    "# 3. Crie uma instância do classificador KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 4. Defina os parâmetros para a busca por hiperparâmetros\n",
    "param_grid = {'n_neighbors': k_values}\n",
    "\n",
    "# # 5. Realize a busca por hiperparâmetros usando validação cruzada\n",
    "# grid_search = GridSearchCV(knn, param_grid, cv=5) # cv é o número de folds na validação cruzada\n",
    "# grid_search.fit(x_train, y_train.ravel())  # Usar y_train.ravel() em vez de y_train\n",
    "\n",
    "# 5. Realize a busca por hiperparâmetros usando validação cruzada\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=7)\n",
    "grid_search.fit(X_train, y_train.values.ravel())  # Converter y_train para um array numpy usando .values.ravel()\n",
    "\n",
    "# 5. Faça previsões no conjunto de teste\n",
    "y_pred =grid_search.predict(X_train)\n",
    "\n",
    "# 6. Métricas de avaliação, Obtenha os resultados da busca por hiperparâmetros\n",
    "confusion = confusion_matrix(y_train, y_pred)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "precision = precision_score(y_train, y_pred, pos_label='Conceder')\n",
    "recall = recall_score(y_train, y_pred, pos_label='Conceder')\n",
    "\n",
    "\n",
    "\n",
    "print(\"Matriz de Confusão:\\n\", confusion)\n",
    "# print(\"Acurácia:\", accuracy)\n",
    "print(\"Acurácia: %.2f%%\" % (accuracy * 100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    " \n",
    "# 6. Obtenha os resultados da busca por hiperparâmetros\n",
    "print(\"Melhores parâmetros: \", grid_search.best_params_)\n",
    "print(\"Melhor acurácia média: \", grid_search.best_score_)\n",
    "\n",
    "# Nesse código, a função GridSearchCV é utilizada para realizar uma busca exaustiva pelos melhores parâmetros. \n",
    "# O parâmetro param_grid especifica os valores que serão experimentados para o hiperparâmetro n_neighbors (valores de K). \n",
    "# O resultado da busca é armazenado em grid_search.best_params_, que contém os melhores parâmetros encontrados, e grid_search.best_score_, \n",
    "# que contém a melhor acurácia média obtida durante a validação cruzada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataframe\n",
    "df_result = df.copy()# veio todas\n",
    "# criar uma col  classificacao\n",
    "df_result['classificacao'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cliente</th>\n",
       "      <th>idade</th>\n",
       "      <th>limite_adicional</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>acertos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8813</th>\n",
       "      <td>1106</td>\n",
       "      <td>58</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>2232</td>\n",
       "      <td>22</td>\n",
       "      <td>Conceder</td>\n",
       "      <td>Negar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>6544</td>\n",
       "      <td>43</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>7255</td>\n",
       "      <td>46</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>8177</td>\n",
       "      <td>47</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>6059</td>\n",
       "      <td>60</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>9608</td>\n",
       "      <td>34</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>10586</td>\n",
       "      <td>52</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>7717</td>\n",
       "      <td>22</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>7199</td>\n",
       "      <td>34</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_cliente  idade limite_adicional classificacao  acertos\n",
       "8813        1106     58            Negar         Negar        1\n",
       "2324        2232     22         Conceder         Negar        0\n",
       "7176        6544     43            Negar         Negar        1\n",
       "794         7255     46            Negar         Negar        1\n",
       "1281        8177     47            Negar         Negar        1\n",
       "2760        6059     60            Negar         Negar        1\n",
       "5264        9608     34            Negar         Negar        1\n",
       "702        10586     52            Negar         Negar        1\n",
       "2253        7717     22            Negar         Negar        1\n",
       "3489        7199     34            Negar         Negar        1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar uma coluna Acertos com 1 e 0 , 1 para conceder e 0 para negar\n",
    "df_result['acertos'] = df_result.loc[:,['id_cliente','limite_adicional','classificacao']].apply(lambda x: 1 if x['limite_adicional'] == x['classificacao'] else 0, axis=1)\n",
    "\n",
    "# Verificando a col criada.\n",
    "df_result.loc[:,['id_cliente','idade','limite_adicional','classificacao','acertos'] ].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz da confusao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      " [[ 146 1359]\n",
      " [ 102 7893]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_train, y_pred)\n",
    "print(\"Matriz de Confusão:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 84.62%\n"
     ]
    }
   ],
   "source": [
    "# 6. Avalie o desempenho do modelo\n",
    "accuracy = mt.accuracy_score(y_train, y_pred)\n",
    "print(\"Acurácia: %.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5887096774193549\n"
     ]
    }
   ],
   "source": [
    "precision = mt.precision_score(y_train, y_pred, pos_label='Conceder')\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.09700996677740864\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_train, y_pred, pos_label='Conceder')\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando o K-nn com 50% dos dados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_cliente</th>\n",
       "      <th>idade</th>\n",
       "      <th>saldo_atual</th>\n",
       "      <th>divida_atual</th>\n",
       "      <th>renda_anual</th>\n",
       "      <th>valor_em_investimentos</th>\n",
       "      <th>taxa_utilizacao_credito</th>\n",
       "      <th>num_emprestimos</th>\n",
       "      <th>num_contas_bancarias</th>\n",
       "      <th>num_cartoes_credito</th>\n",
       "      <th>dias_atraso_dt_venc</th>\n",
       "      <th>num_pgtos_atrasados</th>\n",
       "      <th>num_consultas_credito</th>\n",
       "      <th>taxa_juros</th>\n",
       "      <th>investe_exterior</th>\n",
       "      <th>pessoa_polit_exp</th>\n",
       "      <th>limite_adicional</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>acertos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9112</th>\n",
       "      <td>11211</td>\n",
       "      <td>23</td>\n",
       "      <td>268.764684</td>\n",
       "      <td>4286.15</td>\n",
       "      <td>42311.75284</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>30.52082</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>Negar</td>\n",
       "      <td>Negar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_cliente  idade  saldo_atual  divida_atual  renda_anual  \\\n",
       "9112       11211     23   268.764684       4286.15  42311.75284   \n",
       "\n",
       "      valor_em_investimentos  taxa_utilizacao_credito  num_emprestimos  \\\n",
       "9112                 10000.0                 30.52082                8   \n",
       "\n",
       "      num_contas_bancarias  num_cartoes_credito  dias_atraso_dt_venc  \\\n",
       "9112                     7                    9                   35   \n",
       "\n",
       "      num_pgtos_atrasados  num_consultas_credito  taxa_juros investe_exterior  \\\n",
       "9112                   19                      7          26              Não   \n",
       "\n",
       "     pessoa_polit_exp limite_adicional classificacao  acertos  \n",
       "9112              Não            Negar         Negar        1  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df_result.copy()\n",
    "df1.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "feactures1 =['id_cliente', 'idade', 'saldo_atual', 'divida_atual', 'renda_anual',\n",
    "            'valor_em_investimentos', 'taxa_utilizacao_credito', 'num_emprestimos',\n",
    "            'num_contas_bancarias', 'num_cartoes_credito', 'dias_atraso_dt_venc',\n",
    "            'num_pgtos_atrasados', 'num_consultas_credito', 'taxa_juros','investe_exterior', 'pessoa_polit_exp']\n",
    "label1 = ['limite_adicional'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negar       3997\n",
      "Conceder     752\n",
      "Name: limite_adicional, dtype: int64\n",
      "Negar       0.841651\n",
      "Conceder    0.158349\n",
      "Name: limite_adicional, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#  Dividir os dados por classe \n",
    "dados_conceder1 = df1.loc[df['limite_adicional'] == 'Conceder']\n",
    "dados_negar1   = df1.loc[df['limite_adicional'] == 'Negar']\n",
    "\n",
    "# Selecionar 50% dos dados de cada classe\n",
    "meio_conceder1 = int(0.5 * len(dados_conceder1))\n",
    "meio_negar1 = int(0.5 * len(dados_negar1))\n",
    "\n",
    "# dados_conceder.sample(n=tamanho_conceder, random_state=42) é usado para amostrar aleatoriamente \n",
    "# um número específico de linhas do DataFrame dados_conceder. O argumento n=tamanho_conceder define\n",
    "#  o número de linhas que você deseja amostrar, onde tamanho_conceder é a metade do tamanho total dos\n",
    "#  dados da classe \"Conceder\".\n",
    "# O parâmetro random_state=42 é opcional e usado para garantir que a amostragem seja reproduzível,\n",
    "#  ou seja, produza os mesmos resultados sempre que for executado com o mesmo valor. \n",
    "# Isso é útil para fins de depuração e para garantir que você obtenha a mesma amostra aleatória\n",
    "#  em cada execução.\n",
    "dados_conceder_selecionados1 = dados_conceder1.sample(n=meio_conceder1,random_state=42)\n",
    "\n",
    "# Da mesma forma, essa linha amostra aleatoriamente um número específico de linhas do DataFrame\n",
    "#  dados_negar. O argumento n=tamanho_negar define o número de linhas a serem amostradas,\n",
    "#  onde tamanho_negar é a metade do tamanho total dos dados da classe \"Negar\".\n",
    "# O parâmetro random_state=42 é usado para garantir a reprodutibilidade da amostragem.\n",
    "dados_negar_selecionados1 = dados_negar1.sample(n=meio_negar1, random_state=42)\n",
    "\n",
    "# Concatenar os dados selecionados de cada classe\n",
    "dados_selecionados1 = pd.concat([dados_conceder_selecionados1, dados_negar_selecionados1])\n",
    "\n",
    "# Embaralhar os dados selecionados\n",
    "dados_selecionados1 = dados_selecionados1.sample(frac=1, random_state=42)\n",
    "\n",
    "# contagem de quantos negar/conceder\n",
    "contagem1 = dados_selecionados1.loc[:,'limite_adicional'].value_counts()\n",
    "# Porcentagem da quantidade Negar/Conceder\n",
    "porcentagem1 = dados_selecionados1.loc[:,'limite_adicional'].value_counts(normalize=True)\n",
    "print(contagem1)\n",
    "print(porcentagem1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar os dados selecionados para treinamento do modelo KNN\n",
    "# Divida os dados em conjunto de treinamento\n",
    "X_train1 = dados_selecionados1.loc[:, feactures1]  # Recursos\n",
    "y_train1 = dados_selecionados1.loc[:, label1]  # Classe\n",
    "\n",
    "# Supondo que 'x_train' seja o DataFrame que contém seus dados de treinamento e devemos excluir dados nao relevantes ou que nao seja float/int\n",
    "drop_n_relevante1 = ['investe_exterior', 'pessoa_polit_exp']\n",
    "X_train1 = X_train1.drop(drop_n_relevante1, axis=1)\n",
    "\n",
    "# Essas linhas de código têm como objetivo selecionar uma quantidade igual de amostras aleatórias das classes \"Conceder\" e \"Negar\". O tamanho da amostra é definido como metade do tamanho total de cada classe para obter uma proporção balanceada de 50% para cada classe nos dados selecionados.\n",
    "#  Essas amostras selecionadas serão posteriormente concatenadas para criar um conjunto de dados balanceado que pode ser utilizado para treinar o modelo KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      " [[  73  679]\n",
      " [  54 3943]]\n",
      "Acurácia: 84.57%\n",
      "Precision: 0.5748031496062992\n",
      "Recall: 0.09707446808510638\n",
      "Melhores parâmetros:  {'n_neighbors': 17}\n",
      "Melhor acurácia média:  0.8391247384822007\n"
     ]
    }
   ],
   "source": [
    "# 2. Defina uma lista de valores K para experimentar\n",
    "k_values1 = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "\n",
    "# 3. Crie uma instância do classificador KNN\n",
    "knn1 = KNeighborsClassifier()\n",
    "\n",
    "# 4. Defina os parâmetros para a busca por hiperparâmetros\n",
    "param_grid1 = {'n_neighbors': k_values1}\n",
    "\n",
    "# 5. Realize a busca por hiperparâmetros usando validação cruzada\n",
    "grid_search1 = GridSearchCV(knn1, param_grid1, cv=7) # cv é o número de folds na validação cruzada\n",
    "grid_search1.fit(X_train1, y_train1.values.ravel())  # Converter y_train para um array numpy usando .values.ravel()\n",
    "\n",
    "# Faça previsões no conjunto de teste\n",
    "y_pred1 =grid_search1.predict(X_train1)\n",
    "\n",
    "# 6. Métricas de avaliação, Obtenha os resultados da busca por hiperparâmetros\n",
    "confusion = confusion_matrix(y_train1, y_pred1)\n",
    "accuracy = accuracy_score(y_train1, y_pred1)\n",
    "precision = precision_score(y_train1, y_pred1, pos_label='Conceder')\n",
    "recall = recall_score(y_train1, y_pred1, pos_label='Conceder')\n",
    "\n",
    "print(\"Matriz de Confusão:\\n\", confusion)\n",
    "# print(\"Acurácia:\", accuracy)\n",
    "print(\"Acurácia: %.2f%%\" % (accuracy * 100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    " \n",
    "print(\"Melhores parâmetros: \", grid_search1.best_params_)\n",
    "print(\"Melhor acurácia média: \", grid_search1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando 90% Conceder e 10% Negar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conceder    1354\n",
      "Negar         79\n",
      "Name: limite_adicional, dtype: int64\n",
      "Conceder    0.944871\n",
      "Negar       0.055129\n",
      "Name: limite_adicional, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#  Dividir os dados por classe \n",
    "dados_conceder2 = df.loc[df['limite_adicional'] == 'Conceder']\n",
    "dados_negar2   = df.loc[df['limite_adicional'] == 'Negar']\n",
    "\n",
    "# Selecionar 50% dos dados de cada classe\n",
    "meio_conceder2 = int(0.9 * len(dados_conceder))\n",
    "meio_negar2 = int(0.01 * len(dados_negar))\n",
    "\n",
    "dados_conceder_selecionados2 = dados_conceder2.sample(n=meio_conceder2,random_state=42)\n",
    "dados_negar_selecionados2 = dados_negar2.sample(n=meio_negar2, random_state=42)\n",
    "\n",
    "# Concatenar os dados selecionados de cada classe\n",
    "dados_selecionados2 = pd.concat([dados_conceder_selecionados2, dados_negar_selecionados2])\n",
    "\n",
    "# Embaralhar os dados selecionados\n",
    "dados_selecionados2 = dados_selecionados2.sample(frac=1, random_state=42)\n",
    "\n",
    "# contagem de quantos negar/conceder\n",
    "contagem2 = dados_selecionados2.loc[:,'limite_adicional'].value_counts()\n",
    "# Porcentagem da quantidade Negar/Conceder\n",
    "porcentagem2 = dados_selecionados2.loc[:,'limite_adicional'].value_counts(normalize=True)\n",
    "print(contagem2)\n",
    "print(porcentagem2)\n",
    "\n",
    "feactures2 =['id_cliente', 'idade', 'saldo_atual', 'divida_atual', 'renda_anual',\n",
    "            'valor_em_investimentos', 'taxa_utilizacao_credito', 'num_emprestimos',\n",
    "            'num_contas_bancarias', 'num_cartoes_credito', 'dias_atraso_dt_venc',\n",
    "            'num_pgtos_atrasados', 'num_consultas_credito', 'taxa_juros','investe_exterior', 'pessoa_polit_exp']\n",
    "label2 = ['limite_adicional'] \n",
    "\n",
    "# Utilizar os dados selecionados para treinamento do modelo KNN\n",
    "# Divida os dados em conjunto de treinamento\n",
    "X_train2 = dados_selecionados2.loc[:, feactures2]  # Recursos\n",
    "y_train2 = dados_selecionados2.loc[:, label2]  # Classe\n",
    "\n",
    "# Supondo que 'x_train' seja o DataFrame que contém seus dados de treinamento e devemos excluir dados nao relevantes ou que nao seja float/int\n",
    "drop_n_relevante2 = ['investe_exterior', 'pessoa_polit_exp']\n",
    "X_train2 = X_train2.drop(drop_n_relevante2, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      " [[1354    0]\n",
      " [  69   10]]\n",
      "Acurácia: 95.18%\n",
      "Precision: 0.9515108924806747\n",
      "Recall: 1.0\n",
      "Melhores parâmetros:  {'n_neighbors': 7}\n",
      "Melhor acurácia média:  0.950457744073239\n"
     ]
    }
   ],
   "source": [
    "# 2. Defina uma lista de valores K para experimentar\n",
    "k_values2 = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "\n",
    "# 3. Crie uma instância do classificador KNN\n",
    "knn2 = KNeighborsClassifier()\n",
    "\n",
    "# 4. Defina os parâmetros para a busca por hiperparâmetros\n",
    "param_grid2 = {'n_neighbors': k_values2}\n",
    "\n",
    "# 5. Realize a busca por hiperparâmetros usando validação cruzada\n",
    "grid_search2 = GridSearchCV(knn, param_grid2, cv=7) # cv é o número de folds na validação cruzada\n",
    "grid_search2.fit(X_train2, y_train2.values.ravel())  # Converter y_train para um array numpy usando .values.ravel()\n",
    "\n",
    "# Faça previsões no conjunto de teste\n",
    "y_pred2 =grid_search2.predict(X_train2)\n",
    "\n",
    "# 6. Métricas de avaliação, Obtenha os resultados da busca por hiperparâmetros\n",
    "confusion = confusion_matrix(y_train2, y_pred2)\n",
    "accuracy = accuracy_score(y_train2, y_pred2)\n",
    "precision = precision_score(y_train2, y_pred2, pos_label='Conceder')\n",
    "recall = recall_score(y_train2, y_pred2, pos_label='Conceder')\n",
    "\n",
    "print(\"Matriz de Confusão:\\n\", confusion)\n",
    "# print(\"Acurácia:\", accuracy)\n",
    "print(\"Acurácia: %.2f%%\" % (accuracy * 100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    " \n",
    "print(\"Melhores parâmetros: \", grid_search2.best_params_)\n",
    "print(\"Melhor acurácia média: \", grid_search2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
